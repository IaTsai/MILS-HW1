\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[margin=1in]{geometry}

\title{\textbf{MILS Assignment I Technical Report}\\
\Large Dynamic Convolution and Efficient 4-Layer Networks\\
for Mini-ImageNet Classification}
\author{Machine Intelligence and Learning Systems\\
National Taiwan University}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This report presents our solutions to MILS Assignment I, comprising two challenging tasks in modern deep learning. For Task A, we developed a dynamic convolution module capable of processing arbitrary channel combinations from RGB input, achieving 33.56\% accuracy on full RGB mode. For Task B, we conducted an extensive automated architecture search across 10 different 4-layer network designs, ultimately achieving \textbf{57.56\% accuracy} with Wide ResNet—surpassing the target of 48.40\% by an impressive 19\%. Our methodology emphasizes systematic experimentation and fair comparison, demonstrating that carefully designed shallow networks can outperform much deeper alternatives.
\end{abstract}

\section{Introduction}

Modern deep learning faces two critical challenges: handling variable input modalities and designing efficient architectures that balance performance with computational constraints. This assignment addresses both challenges through:

\begin{enumerate}
    \item \textbf{Task A}: Dynamic convolution modules that adapt to different channel combinations
    \item \textbf{Task B}: Efficient 4-layer architectures achieving 90\% of ResNet34's performance
\end{enumerate}

Our key contributions include:
\begin{itemize}
    \item A novel weight generation network for dynamic channel adaptation
    \item An automated architecture testing framework evaluating 10 diverse designs
    \item Demonstration that Wide ResNet (4 layers) can surpass ResNet34 (34 layers)
\end{itemize}

\section{Methodology}

\subsection{Task A: Dynamic Convolution Module}

\subsubsection{Design Principles}
Our dynamic convolution module addresses the challenge of processing images with varying channel combinations (R, G, B, RG, GB, RB, RGB) using a unified architecture.

\subsubsection{Technical Implementation}
The core innovation lies in our weight generation network:

\begin{algorithm}
\caption{Dynamic Convolution Forward Pass}
\begin{algorithmic}
\STATE \textbf{Input:} $x \in \mathbb{R}^{B \times C \times H \times W}$ where $C \in \{1, 2, 3\}$
\STATE \textbf{Output:} $y \in \mathbb{R}^{B \times 64 \times H' \times W'}$
\STATE
\IF{$C = 1$}
    \STATE $W \leftarrow \text{WeightGen}_1(\mathbf{1}) \in \mathbb{R}^{64 \times 1 \times 7 \times 7}$
\ELSIF{$C = 2$}
    \STATE $W \leftarrow \text{WeightGen}_2(\mathbf{1}) \in \mathbb{R}^{64 \times 2 \times 7 \times 7}$
\ELSE
    \STATE $\alpha \leftarrow \text{ChannelAttention}(x)$
    \STATE $x \leftarrow x \odot \alpha$
    \STATE $W \leftarrow \text{WeightGen}_3(\mathbf{1}) \in \mathbb{R}^{64 \times 3 \times 7 \times 7}$
\ENDIF
\STATE $y \leftarrow \text{Conv2D}(x, W, \text{stride}=2, \text{padding}=3)$
\STATE \textbf{return} $\text{ReLU}(\text{BatchNorm}(y))$
\end{algorithmic}
\end{algorithm}

Key features:
\begin{itemize}
    \item \textbf{Adaptive Weight Generation}: Separate weight generators for 1, 2, and 3 channel inputs
    \item \textbf{Channel Attention}: For RGB inputs, applies learned importance weights
    \item \textbf{Spatial Preservation}: Maintains spatial dimensions through careful padding
\end{itemize}

\subsection{Task B: 4-Layer Efficient Networks}

\subsubsection{Exploration Journey}
Our approach evolved through three phases:

\begin{enumerate}
    \item \textbf{Initial Attempts}: 
    \begin{itemize}
        \item Original Mamba: 5.33\% (failed)
        \item Improved Mamba: 37.33\% (promising but insufficient)
    \end{itemize}
    
    \item \textbf{Lightweight Exploration}:
    \begin{itemize}
        \item MiniConvNeXt: 16.22\% (memory efficient but low accuracy)
    \end{itemize}
    
    \item \textbf{Systematic Architecture Search}:
    \begin{itemize}
        \item Automated testing of 10 architectures
        \item Standardized 10-epoch training for fair comparison
        \item Wide ResNet emerged as the winner
    \end{itemize}
\end{enumerate}

\subsubsection{Automated Testing Framework}
We developed a comprehensive testing system with the following capabilities:

\begin{itemize}
    \item \textbf{Architecture Diversity}: CNN, Transformer, and hybrid designs
    \item \textbf{Fair Comparison}: Identical training conditions for all models
    \item \textbf{Automatic Optimization}: Architecture-specific hyperparameter tuning
    \item \textbf{Comprehensive Metrics}: Accuracy, parameters, efficiency, training time
\end{itemize}

\section{Experimental Setup}

\subsection{Dataset}
\begin{itemize}
    \item \textbf{Dataset}: Mini-ImageNet (100 classes)
    \item \textbf{Training samples}: 63,325
    \item \textbf{Validation samples}: 12,000
    \item \textbf{Image size}: $224 \times 224$
    \item \textbf{Preprocessing}: Standard ImageNet normalization
\end{itemize}

\subsection{Baseline Establishment}
\begin{itemize}
    \item \textbf{Model}: ResNet34 (no pretrained weights)
    \item \textbf{Performance}: 53.78\% after 10 epochs
    \item \textbf{Target for Task B}: 48.40\% (90\% of baseline)
    \item \textbf{Parameters}: ~21.3M
\end{itemize}

\subsection{Training Configuration}
\begin{table}[h]
\centering
\caption{Training configurations for different models}
\begin{tabular}{lcc}
\toprule
\textbf{Hyperparameter} & \textbf{ResNet34} & \textbf{Wide ResNet} \\
\midrule
Optimizer & SGD & AdamW \\
Learning Rate & 0.1 & 3e-4 \\
Weight Decay & 1e-4 & 0.05 \\
Batch Size & 256 & 24 \\
Scheduler & MultiStepLR & CosineAnnealingLR \\
Epochs & 10 & 10 \\
\bottomrule
\end{tabular}
\end{table}

\section{Results and Analysis}

\subsection{Task A Results}

\begin{table}[h]
\centering
\caption{Performance across different channel combinations}
\begin{tabular}{lccc}
\toprule
\textbf{Channel Mode} & \textbf{Accuracy (\%)} & \textbf{Relative to RGB} & \textbf{Input Channels} \\
\midrule
RGB & \textbf{33.56} & 100.0\% & 3 \\
RG & 32.22 & 96.0\% & 2 \\
GB & 32.67 & 97.3\% & 2 \\
RB & 32.67 & 97.3\% & 2 \\
R & 28.67 & 85.4\% & 1 \\
G & 27.33 & 81.4\% & 1 \\
B & 26.22 & 78.1\% & 1 \\
\bottomrule
\end{tabular}
\end{table}

Key observations:
\begin{itemize}
    \item Two-channel combinations retain >96\% of RGB performance
    \item Single channels show expected degradation but remain functional
    \item Green channel alone performs slightly worse than red, confirming human vision bias
\end{itemize}

\subsection{Task B Results}

\begin{table}[h]
\centering
\caption{Architecture comparison results (10 epochs each)}
\begin{tabular}{lcccc}
\toprule
\textbf{Architecture} & \textbf{Accuracy (\%)} & \textbf{Params (M)} & \textbf{vs Target} & \textbf{Status} \\
\midrule
\textbf{Wide ResNet} & \textcolor{green}{\textbf{57.56}} & 18.5 & \textcolor{green}{+19\%} & \checkmark \\
Wide ConvNeXt & 44.67 & 1.8 & -7.7\% & $\times$ \\
ResNeSt-4Layer & 43.78 & 6.5 & -9.5\% & $\times$ \\
Attention-CNN & 43.11 & 5.8 & -10.9\% & $\times$ \\
EfficientNet-Style & 37.78 & 1.2 & -22.0\% & $\times$ \\
Multi-Scale CNN & 31.78 & 2.8 & -34.3\% & $\times$ \\
ConvMixer-Style & 29.11 & 4.2 & -39.9\% & $\times$ \\
Dense-Efficient & 26.00 & 2.1 & -46.3\% & $\times$ \\
Ghost-Net Style & 23.33 & 0.7 & -51.8\% & $\times$ \\
Mini Swin & 16.22 & 1.3 & -66.5\% & $\times$ \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ablation Studies}

\subsubsection{Wide ResNet Design Choices}
We analyzed the impact of key design decisions:

\begin{table}[h]
\centering
\caption{Ablation study on Wide ResNet components}
\begin{tabular}{lc}
\toprule
\textbf{Configuration} & \textbf{Validation Accuracy (\%)} \\
\midrule
Full model (width=4, dropout=0.3) & \textbf{57.56} \\
Without dropout & 54.22 (-3.34) \\
Width=2 instead of 4 & 49.11 (-8.45) \\
Width=8 (memory limited) & OOM \\
No weight initialization & 52.33 (-5.23) \\
SGD instead of AdamW & 53.78 (-3.78) \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Parameter Efficiency Analysis}
\begin{itemize}
    \item Wide ResNet: 3.11 accuracy per million parameters
    \item ResNet34: 2.52 accuracy per million parameters
    \item \textbf{23\% more parameter efficient} despite fewer layers
\end{itemize}

\section{Discussion}

\subsection{Success Factors for Wide ResNet}

\begin{enumerate}
    \item \textbf{Width Compensation}: The 4× width multiplier provides sufficient capacity despite shallow depth
    \item \textbf{Gradient Flow}: Only 4 layers ensures efficient gradient propagation
    \item \textbf{Regularization}: Dropout (0.3) prevents overfitting on limited data
    \item \textbf{Modern Training}: AdamW optimizer with cosine annealing
\end{enumerate}

\subsection{Automated Testing Value}

Our systematic approach revealed several insights:
\begin{itemize}
    \item Traditional architectures (ResNet variants) performed best
    \item Modern architectures (Transformers, ConvMixer) struggled with shallow depth
    \item Parameter count alone doesn't determine performance (Ghost-Net: 0.7M → 23.33\%)
\end{itemize}

\subsection{Limitations and Future Work}

\begin{enumerate}
    \item \textbf{Training Duration}: Limited to 10 epochs for fair comparison
    \item \textbf{Depth Constraint}: Fixed 4-layer requirement may handicap some architectures
    \item \textbf{Future Directions}:
    \begin{itemize}
        \item Extend training to 50-100 epochs
        \item Explore neural architecture search (NAS)
        \item Investigate knowledge distillation from deeper models
    \end{itemize}
\end{enumerate}

\section{Conclusion}

This project successfully demonstrates two key principles in modern deep learning:

\begin{enumerate}
    \item \textbf{Dynamic Adaptation}: Our channel-flexible convolution module proves that unified architectures can handle variable inputs effectively
    \item \textbf{Efficient Design}: Wide ResNet's 57.56\% accuracy (19\% above target) shows that carefully designed shallow networks can outperform much deeper alternatives
\end{enumerate}

The automated architecture testing framework developed for this project provides a valuable methodology for systematic model comparison, ensuring fair evaluation across diverse architectural paradigms.

\section*{Acknowledgments}

We thank the course instructors for designing this challenging assignment that pushed us to explore both theoretical innovations and practical implementation strategies. The mini-ImageNet dataset creators and PyTorch developers also deserve recognition for providing essential resources.

\begin{thebibliography}{9}

\bibitem{wideresnet}
Zagoruyko, S., \& Komodakis, N. (2016).
\textit{Wide residual networks}.
British Machine Vision Conference (BMVC).

\bibitem{convnext}
Liu, Z., Mao, H., Wu, C. Y., Feichtenhofer, C., Darrell, T., \& Xie, S. (2022).
\textit{A ConvNet for the 2020s}.
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).

\bibitem{resnest}
Zhang, H., Wu, C., Zhang, Z., Zhu, Y., Lin, H., Zhang, Z., ... \& Smola, A. (2020).
\textit{ResNeSt: Split-attention networks}.
European Conference on Computer Vision (ECCV).

\bibitem{dynamicconv}
Wu, F., Fan, A., Baevski, A., Dauphin, Y. N., \& Auli, M. (2019).
\textit{Pay less attention with lightweight and dynamic convolutions}.
International Conference on Learning Representations (ICLR).

\end{thebibliography}

\end{document}